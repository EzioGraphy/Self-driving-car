{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "from IPython.display import display \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "#from kt_utils import *\n",
    "from keras import optimizers\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load images\n",
    "import glob\n",
    "filelist = glob.glob(os.path.join('images/a','*.jpg'))\n",
    "a = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "ay = np.zeros(a.shape[0])\n",
    "\n",
    "filelist = glob.glob(os.path.join('images/w','*.jpg'))\n",
    "w = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "wy = np.ones(w.shape[0])\n",
    "\n",
    "filelist = glob.glob(os.path.join('images/d','*.jpg'))\n",
    "d = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "dy = np.ones(d.shape[0])*2\n",
    "\n",
    "filelist = glob.glob(os.path.join('images/q','*.jpg'))\n",
    "q = np.array([np.array(Image.open(fname)) for fname in filelist])\n",
    "qy = np.ones(q.shape[0])*3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly split into train and test\n",
    "aX, aY = shuffle(a, ay, random_state=0)\n",
    "wX, wY = shuffle(w, wy, random_state=0)\n",
    "dX, dY = shuffle(d, dy, random_state=0)\n",
    "qX, qY = shuffle(q, qy, random_state=0)\n",
    "del (a, ay, w, wy, d, dy, q, qy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decrease sizhttp://localhost:8891/notebooks/MLmodel.ipynb#e of w\n",
    "length_d = int(dX.shape[0] * 1.3)\n",
    "wX = wX[:length_d]\n",
    "wY = wY[:length_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly split into train and test\n",
    "allX = np.concatenate((qX, np.concatenate((np.concatenate((aX , wX)) , dX))))\n",
    "allY = np.concatenate((qY, np.concatenate((np.concatenate((ay , wY)) , dY))))\n",
    "\n",
    "#one hot encode\n",
    "allY = pd.get_dummies(allY).values\n",
    "\n",
    "del (wX, wY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allX, allY = shuffle(allX, allY, random_state=0)\n",
    "percent = int(allX.shape[0]*0.17)\n",
    "testX = allX[:percent]\n",
    "trainX = allX[percent:]\n",
    "testY =allY[:percent]\n",
    "trainY =allY[percent:]\n",
    "\n",
    "del (allX, allY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "#Show test image\n",
    "img = Image.fromarray(testX[10], 'RGB')\n",
    "img.show()\n",
    "print(testY[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have trainX, trainY, testX and testY with test being 17% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the Model.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(6, (6,6), strides=(1, 1), name='conv0', padding = 'same')(X_input)\n",
    "    X = BatchNormalization(axis=3, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool0')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(16, (5,5), strides=(1, 1), name='conv1', padding = 'valid')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block applied to X\n",
    "    X = Conv2D(8, (3, 3), strides=(1, 1), name='conv2', padding = 'valid')(X)\n",
    "    X = BatchNormalization(axis=3, name='bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool2')(X)\n",
    "\n",
    "    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(units=4, activation='sigmoid', name='fc')(X)\n",
    "    \n",
    "\n",
    "    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n",
    "    model = Model(inputs=X_input, outputs=X, name='cModel')\n",
    "\n",
    "    return model\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "endModel = cModel(trainX.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers.SGD(lr=0.0001, momentum=0.0, decay=0.0, nesterov=False)\n",
    "endModel.compile('Adam', 'mean_squared_error', metrics=['accuracy'])\n",
    "#SGD ~40\n",
    "#RMSprop ~90\n",
    "#Adam ~94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "741/741 [==============================] - 17s 23ms/step - loss: 0.1765 - acc: 0.4548\n",
      "Epoch 2/5\n",
      "741/741 [==============================] - 16s 22ms/step - loss: 0.1289 - acc: 0.6491\n",
      "Epoch 3/5\n",
      "741/741 [==============================] - 16s 22ms/step - loss: 0.1076 - acc: 0.7045\n",
      "Epoch 4/5\n",
      "741/741 [==============================] - 16s 22ms/step - loss: 0.0950 - acc: 0.7557\n",
      "Epoch 5/5\n",
      "741/741 [==============================] - 16s 22ms/step - loss: 0.0857 - acc: 0.7814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12e668630>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endModel.fit(trainX, trainY, epochs=5, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 2s 11ms/step\n",
      "\n",
      "Loss = 0.1402729588825971\n",
      "Test Accuracy = 0.5960264861188977\n"
     ]
    }
   ],
   "source": [
    "preds = endModel.evaluate(testX, testY, batch_size=32, verbose=1, sample_weight=None)\n",
    "\n",
    "print()\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.2679826e-02 8.6978137e-01 3.9318240e-01 1.4338831e-05]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "results = (endModel.predict(np.expand_dims(testX[8], axis=0)))\n",
    "#results = (endModel.predict(testX[6:7]))\n",
    "print(results)\n",
    "results = np.argmax(results, axis = 1)  \n",
    "           \n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "endModel.save('my_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del endModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "endModel = load_model('my_model.h5')\n",
    "yFit = endModel.predict(np.expand_dims(testX[8], axis=0))\n",
    "yFit = np.argmax(yFit, axis = 1)  \n",
    "print()\n",
    "print(yFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
